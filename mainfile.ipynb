{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geJlq3ruqf5n",
        "outputId": "fef0b3f0-9a16-4ea3-9d96-2b02e33f6f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training XGBoost model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:27:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training Accuracy: 94.93%\n",
            "üìÅ submission.csv saved successfully with ID and WeightCategory columns!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 1. Load data\n",
        "# =============================================\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Preserve test IDs for final submission\n",
        "test_ids = test['id'].copy()\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 2. Encode target labels\n",
        "# =============================================\n",
        "target_col = 'WeightCategory'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(train[target_col])\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 3. Prepare features\n",
        "# =============================================\n",
        "# Drop target and ID from training set\n",
        "X = train.drop(columns=[target_col, 'id'])\n",
        "\n",
        "# Drop ID from test set\n",
        "test_features = test.drop(columns=['id'])\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 4. One-hot encode categorical features\n",
        "# =============================================\n",
        "X = pd.get_dummies(X)\n",
        "test_features = pd.get_dummies(test_features)\n",
        "\n",
        "# Align columns between train and test\n",
        "X, test_features = X.align(test_features, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 5. Scale features\n",
        "# =============================================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 6. Train XGBoost Classifier\n",
        "# =============================================\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Define number of classes from your label set\n",
        "num_classes = len(np.unique(y))  # Ensure 'y' is defined earlier\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=582,\n",
        "    learning_rate=0.035,  # 'eta' in param dict\n",
        "    max_depth=9,\n",
        "    subsample=0.476,\n",
        "    colsample_bytree=0.55,\n",
        "    gamma=0.591,\n",
        "    min_child_weight=2,\n",
        "    reg_alpha=0.449,\n",
        "    reg_lambda=2.0,\n",
        "    random_state=42,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training XGBoost model...\")\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 7. Evaluate Training Accuracy\n",
        "# =============================================\n",
        "train_pred = model.predict(X_scaled)\n",
        "train_accuracy = accuracy_score(y, train_pred)\n",
        "print(f\"‚úÖ Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 8. Predict on Test Set\n",
        "# =============================================\n",
        "test_pred_numeric = model.predict(test_scaled)\n",
        "test_pred_labels = label_encoder.inverse_transform(test_pred_numeric)\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ 9. Save Predictions\n",
        "# =============================================\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'WeightCategory': test_pred_labels\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"üìÅ submission.csv saved successfully with ID and WeightCategory columns!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BCjwl9O76X4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"multi:softprob\",\n",
        "    \"num_class\": len(np.unique(y_train)),\n",
        "    \"eval_metric\": \"mlogloss\",\n",
        "    \"learning_rate\": 0.025,\n",
        "    \"max_depth\": 7,\n",
        "    \"subsample\": 0.75,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"gamma\": 0.5,\n",
        "    \"min_child_weight\": 3,\n",
        "    \"reg_alpha\": 0.4493,\n",
        "    \"reg_lambda\": 1.0,\n",
        "    \"random_state\": 42\n",
        "}\n",
        "\n",
        "\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=600,\n",
        "    evals=[(dval, \"validation\")],\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "# Evaluate validation performance\n",
        "val_pred_proba = model.predict(dval) # Predict probabilities on DMatrix\n",
        "val_pred = np.argmax(val_pred_proba, axis=1) # Get predicted class labels from probabilities\n",
        "\n",
        "val_accuracy = accuracy_score(y_val, val_pred)\n",
        "print(f\"üéØ Validation Accuracy: {val_accuracy * 100:.4f}%\")\n",
        "print(\"\\nüìä Classification Report:\\n\", classification_report(y_val, val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu4ItBt-zQOe",
        "outputId": "4bf48002-2a5b-4182-9749-5844727853b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-mlogloss:1.88597\n",
            "[1]\tvalidation-mlogloss:1.82740\n",
            "[2]\tvalidation-mlogloss:1.77202\n",
            "[3]\tvalidation-mlogloss:1.72361\n",
            "[4]\tvalidation-mlogloss:1.67729\n",
            "[5]\tvalidation-mlogloss:1.63198\n",
            "[6]\tvalidation-mlogloss:1.59079\n",
            "[7]\tvalidation-mlogloss:1.55142\n",
            "[8]\tvalidation-mlogloss:1.51458\n",
            "[9]\tvalidation-mlogloss:1.47666\n",
            "[10]\tvalidation-mlogloss:1.44122\n",
            "[11]\tvalidation-mlogloss:1.40730\n",
            "[12]\tvalidation-mlogloss:1.37906\n",
            "[13]\tvalidation-mlogloss:1.35172\n",
            "[14]\tvalidation-mlogloss:1.32293\n",
            "[15]\tvalidation-mlogloss:1.29564\n",
            "[16]\tvalidation-mlogloss:1.27059\n",
            "[17]\tvalidation-mlogloss:1.24550\n",
            "[18]\tvalidation-mlogloss:1.22101\n",
            "[19]\tvalidation-mlogloss:1.19840\n",
            "[20]\tvalidation-mlogloss:1.17560\n",
            "[21]\tvalidation-mlogloss:1.15219\n",
            "[22]\tvalidation-mlogloss:1.12915\n",
            "[23]\tvalidation-mlogloss:1.10844\n",
            "[24]\tvalidation-mlogloss:1.08980\n",
            "[25]\tvalidation-mlogloss:1.06939\n",
            "[26]\tvalidation-mlogloss:1.05041\n",
            "[27]\tvalidation-mlogloss:1.03145\n",
            "[28]\tvalidation-mlogloss:1.01202\n",
            "[29]\tvalidation-mlogloss:0.99506\n",
            "[30]\tvalidation-mlogloss:0.97768\n",
            "[31]\tvalidation-mlogloss:0.96128\n",
            "[32]\tvalidation-mlogloss:0.94581\n",
            "[33]\tvalidation-mlogloss:0.93029\n",
            "[34]\tvalidation-mlogloss:0.91546\n",
            "[35]\tvalidation-mlogloss:0.90168\n",
            "[36]\tvalidation-mlogloss:0.88657\n",
            "[37]\tvalidation-mlogloss:0.87370\n",
            "[38]\tvalidation-mlogloss:0.86039\n",
            "[39]\tvalidation-mlogloss:0.84776\n",
            "[40]\tvalidation-mlogloss:0.83470\n",
            "[41]\tvalidation-mlogloss:0.82240\n",
            "[42]\tvalidation-mlogloss:0.81069\n",
            "[43]\tvalidation-mlogloss:0.79872\n",
            "[44]\tvalidation-mlogloss:0.78811\n",
            "[45]\tvalidation-mlogloss:0.77747\n",
            "[46]\tvalidation-mlogloss:0.76694\n",
            "[47]\tvalidation-mlogloss:0.75669\n",
            "[48]\tvalidation-mlogloss:0.74617\n",
            "[49]\tvalidation-mlogloss:0.73555\n",
            "[50]\tvalidation-mlogloss:0.72651\n",
            "[51]\tvalidation-mlogloss:0.71694\n",
            "[52]\tvalidation-mlogloss:0.70781\n",
            "[53]\tvalidation-mlogloss:0.69844\n",
            "[54]\tvalidation-mlogloss:0.69025\n",
            "[55]\tvalidation-mlogloss:0.68243\n",
            "[56]\tvalidation-mlogloss:0.67355\n",
            "[57]\tvalidation-mlogloss:0.66552\n",
            "[58]\tvalidation-mlogloss:0.65780\n",
            "[59]\tvalidation-mlogloss:0.65068\n",
            "[60]\tvalidation-mlogloss:0.64271\n",
            "[61]\tvalidation-mlogloss:0.63533\n",
            "[62]\tvalidation-mlogloss:0.62803\n",
            "[63]\tvalidation-mlogloss:0.62085\n",
            "[64]\tvalidation-mlogloss:0.61412\n",
            "[65]\tvalidation-mlogloss:0.60758\n",
            "[66]\tvalidation-mlogloss:0.60128\n",
            "[67]\tvalidation-mlogloss:0.59542\n",
            "[68]\tvalidation-mlogloss:0.58930\n",
            "[69]\tvalidation-mlogloss:0.58396\n",
            "[70]\tvalidation-mlogloss:0.57758\n",
            "[71]\tvalidation-mlogloss:0.57209\n",
            "[72]\tvalidation-mlogloss:0.56643\n",
            "[73]\tvalidation-mlogloss:0.56112\n",
            "[74]\tvalidation-mlogloss:0.55593\n",
            "[75]\tvalidation-mlogloss:0.55029\n",
            "[76]\tvalidation-mlogloss:0.54537\n",
            "[77]\tvalidation-mlogloss:0.54021\n",
            "[78]\tvalidation-mlogloss:0.53498\n",
            "[79]\tvalidation-mlogloss:0.52974\n",
            "[80]\tvalidation-mlogloss:0.52530\n",
            "[81]\tvalidation-mlogloss:0.52045\n",
            "[82]\tvalidation-mlogloss:0.51553\n",
            "[83]\tvalidation-mlogloss:0.51080\n",
            "[84]\tvalidation-mlogloss:0.50620\n",
            "[85]\tvalidation-mlogloss:0.50188\n",
            "[86]\tvalidation-mlogloss:0.49757\n",
            "[87]\tvalidation-mlogloss:0.49353\n",
            "[88]\tvalidation-mlogloss:0.48944\n",
            "[89]\tvalidation-mlogloss:0.48532\n",
            "[90]\tvalidation-mlogloss:0.48144\n",
            "[91]\tvalidation-mlogloss:0.47766\n",
            "[92]\tvalidation-mlogloss:0.47381\n",
            "[93]\tvalidation-mlogloss:0.46980\n",
            "[94]\tvalidation-mlogloss:0.46618\n",
            "[95]\tvalidation-mlogloss:0.46282\n",
            "[96]\tvalidation-mlogloss:0.45922\n",
            "[97]\tvalidation-mlogloss:0.45609\n",
            "[98]\tvalidation-mlogloss:0.45251\n",
            "[99]\tvalidation-mlogloss:0.44923\n",
            "[100]\tvalidation-mlogloss:0.44603\n",
            "[101]\tvalidation-mlogloss:0.44305\n",
            "[102]\tvalidation-mlogloss:0.44032\n",
            "[103]\tvalidation-mlogloss:0.43749\n",
            "[104]\tvalidation-mlogloss:0.43519\n",
            "[105]\tvalidation-mlogloss:0.43217\n",
            "[106]\tvalidation-mlogloss:0.42942\n",
            "[107]\tvalidation-mlogloss:0.42679\n",
            "[108]\tvalidation-mlogloss:0.42451\n",
            "[109]\tvalidation-mlogloss:0.42181\n",
            "[110]\tvalidation-mlogloss:0.41916\n",
            "[111]\tvalidation-mlogloss:0.41673\n",
            "[112]\tvalidation-mlogloss:0.41419\n",
            "[113]\tvalidation-mlogloss:0.41186\n",
            "[114]\tvalidation-mlogloss:0.40952\n",
            "[115]\tvalidation-mlogloss:0.40713\n",
            "[116]\tvalidation-mlogloss:0.40510\n",
            "[117]\tvalidation-mlogloss:0.40321\n",
            "[118]\tvalidation-mlogloss:0.40125\n",
            "[119]\tvalidation-mlogloss:0.39922\n",
            "[120]\tvalidation-mlogloss:0.39738\n",
            "[121]\tvalidation-mlogloss:0.39544\n",
            "[122]\tvalidation-mlogloss:0.39360\n",
            "[123]\tvalidation-mlogloss:0.39161\n",
            "[124]\tvalidation-mlogloss:0.38961\n",
            "[125]\tvalidation-mlogloss:0.38781\n",
            "[126]\tvalidation-mlogloss:0.38599\n",
            "[127]\tvalidation-mlogloss:0.38391\n",
            "[128]\tvalidation-mlogloss:0.38191\n",
            "[129]\tvalidation-mlogloss:0.38015\n",
            "[130]\tvalidation-mlogloss:0.37850\n",
            "[131]\tvalidation-mlogloss:0.37673\n",
            "[132]\tvalidation-mlogloss:0.37514\n",
            "[133]\tvalidation-mlogloss:0.37365\n",
            "[134]\tvalidation-mlogloss:0.37201\n",
            "[135]\tvalidation-mlogloss:0.37047\n",
            "[136]\tvalidation-mlogloss:0.36895\n",
            "[137]\tvalidation-mlogloss:0.36737\n",
            "[138]\tvalidation-mlogloss:0.36615\n",
            "[139]\tvalidation-mlogloss:0.36465\n",
            "[140]\tvalidation-mlogloss:0.36337\n",
            "[141]\tvalidation-mlogloss:0.36200\n",
            "[142]\tvalidation-mlogloss:0.36067\n",
            "[143]\tvalidation-mlogloss:0.35941\n",
            "[144]\tvalidation-mlogloss:0.35818\n",
            "[145]\tvalidation-mlogloss:0.35694\n",
            "[146]\tvalidation-mlogloss:0.35591\n",
            "[147]\tvalidation-mlogloss:0.35453\n",
            "[148]\tvalidation-mlogloss:0.35340\n",
            "[149]\tvalidation-mlogloss:0.35204\n",
            "[150]\tvalidation-mlogloss:0.35088\n",
            "[151]\tvalidation-mlogloss:0.34972\n",
            "[152]\tvalidation-mlogloss:0.34839\n",
            "[153]\tvalidation-mlogloss:0.34735\n",
            "[154]\tvalidation-mlogloss:0.34636\n",
            "[155]\tvalidation-mlogloss:0.34523\n",
            "[156]\tvalidation-mlogloss:0.34422\n",
            "[157]\tvalidation-mlogloss:0.34331\n",
            "[158]\tvalidation-mlogloss:0.34221\n",
            "[159]\tvalidation-mlogloss:0.34128\n",
            "[160]\tvalidation-mlogloss:0.34026\n",
            "[161]\tvalidation-mlogloss:0.33932\n",
            "[162]\tvalidation-mlogloss:0.33840\n",
            "[163]\tvalidation-mlogloss:0.33736\n",
            "[164]\tvalidation-mlogloss:0.33644\n",
            "[165]\tvalidation-mlogloss:0.33558\n",
            "[166]\tvalidation-mlogloss:0.33466\n",
            "[167]\tvalidation-mlogloss:0.33380\n",
            "[168]\tvalidation-mlogloss:0.33291\n",
            "[169]\tvalidation-mlogloss:0.33201\n",
            "[170]\tvalidation-mlogloss:0.33126\n",
            "[171]\tvalidation-mlogloss:0.33039\n",
            "[172]\tvalidation-mlogloss:0.32965\n",
            "[173]\tvalidation-mlogloss:0.32879\n",
            "[174]\tvalidation-mlogloss:0.32800\n",
            "[175]\tvalidation-mlogloss:0.32725\n",
            "[176]\tvalidation-mlogloss:0.32645\n",
            "[177]\tvalidation-mlogloss:0.32571\n",
            "[178]\tvalidation-mlogloss:0.32499\n",
            "[179]\tvalidation-mlogloss:0.32422\n",
            "[180]\tvalidation-mlogloss:0.32355\n",
            "[181]\tvalidation-mlogloss:0.32285\n",
            "[182]\tvalidation-mlogloss:0.32216\n",
            "[183]\tvalidation-mlogloss:0.32147\n",
            "[184]\tvalidation-mlogloss:0.32089\n",
            "[185]\tvalidation-mlogloss:0.32032\n",
            "[186]\tvalidation-mlogloss:0.31961\n",
            "[187]\tvalidation-mlogloss:0.31898\n",
            "[188]\tvalidation-mlogloss:0.31829\n",
            "[189]\tvalidation-mlogloss:0.31765\n",
            "[190]\tvalidation-mlogloss:0.31708\n",
            "[191]\tvalidation-mlogloss:0.31652\n",
            "[192]\tvalidation-mlogloss:0.31594\n",
            "[193]\tvalidation-mlogloss:0.31525\n",
            "[194]\tvalidation-mlogloss:0.31467\n",
            "[195]\tvalidation-mlogloss:0.31413\n",
            "[196]\tvalidation-mlogloss:0.31354\n",
            "[197]\tvalidation-mlogloss:0.31296\n",
            "[198]\tvalidation-mlogloss:0.31249\n",
            "[199]\tvalidation-mlogloss:0.31199\n",
            "[200]\tvalidation-mlogloss:0.31151\n",
            "[201]\tvalidation-mlogloss:0.31101\n",
            "[202]\tvalidation-mlogloss:0.31062\n",
            "[203]\tvalidation-mlogloss:0.31006\n",
            "[204]\tvalidation-mlogloss:0.30954\n",
            "[205]\tvalidation-mlogloss:0.30902\n",
            "[206]\tvalidation-mlogloss:0.30853\n",
            "[207]\tvalidation-mlogloss:0.30811\n",
            "[208]\tvalidation-mlogloss:0.30764\n",
            "[209]\tvalidation-mlogloss:0.30720\n",
            "[210]\tvalidation-mlogloss:0.30688\n",
            "[211]\tvalidation-mlogloss:0.30640\n",
            "[212]\tvalidation-mlogloss:0.30587\n",
            "[213]\tvalidation-mlogloss:0.30545\n",
            "[214]\tvalidation-mlogloss:0.30503\n",
            "[215]\tvalidation-mlogloss:0.30466\n",
            "[216]\tvalidation-mlogloss:0.30432\n",
            "[217]\tvalidation-mlogloss:0.30402\n",
            "[218]\tvalidation-mlogloss:0.30362\n",
            "[219]\tvalidation-mlogloss:0.30323\n",
            "[220]\tvalidation-mlogloss:0.30278\n",
            "[221]\tvalidation-mlogloss:0.30239\n",
            "[222]\tvalidation-mlogloss:0.30201\n",
            "[223]\tvalidation-mlogloss:0.30157\n",
            "[224]\tvalidation-mlogloss:0.30115\n",
            "[225]\tvalidation-mlogloss:0.30080\n",
            "[226]\tvalidation-mlogloss:0.30049\n",
            "[227]\tvalidation-mlogloss:0.30017\n",
            "[228]\tvalidation-mlogloss:0.29989\n",
            "[229]\tvalidation-mlogloss:0.29952\n",
            "[230]\tvalidation-mlogloss:0.29917\n",
            "[231]\tvalidation-mlogloss:0.29888\n",
            "[232]\tvalidation-mlogloss:0.29857\n",
            "[233]\tvalidation-mlogloss:0.29826\n",
            "[234]\tvalidation-mlogloss:0.29791\n",
            "[235]\tvalidation-mlogloss:0.29756\n",
            "[236]\tvalidation-mlogloss:0.29732\n",
            "[237]\tvalidation-mlogloss:0.29700\n",
            "[238]\tvalidation-mlogloss:0.29665\n",
            "[239]\tvalidation-mlogloss:0.29635\n",
            "[240]\tvalidation-mlogloss:0.29603\n",
            "[241]\tvalidation-mlogloss:0.29579\n",
            "[242]\tvalidation-mlogloss:0.29549\n",
            "[243]\tvalidation-mlogloss:0.29515\n",
            "[244]\tvalidation-mlogloss:0.29490\n",
            "[245]\tvalidation-mlogloss:0.29468\n",
            "[246]\tvalidation-mlogloss:0.29435\n",
            "[247]\tvalidation-mlogloss:0.29409\n",
            "[248]\tvalidation-mlogloss:0.29392\n",
            "[249]\tvalidation-mlogloss:0.29366\n",
            "[250]\tvalidation-mlogloss:0.29341\n",
            "[251]\tvalidation-mlogloss:0.29313\n",
            "[252]\tvalidation-mlogloss:0.29286\n",
            "[253]\tvalidation-mlogloss:0.29257\n",
            "[254]\tvalidation-mlogloss:0.29233\n",
            "[255]\tvalidation-mlogloss:0.29218\n",
            "[256]\tvalidation-mlogloss:0.29195\n",
            "[257]\tvalidation-mlogloss:0.29172\n",
            "[258]\tvalidation-mlogloss:0.29139\n",
            "[259]\tvalidation-mlogloss:0.29115\n",
            "[260]\tvalidation-mlogloss:0.29086\n",
            "[261]\tvalidation-mlogloss:0.29056\n",
            "[262]\tvalidation-mlogloss:0.29036\n",
            "[263]\tvalidation-mlogloss:0.29012\n",
            "[264]\tvalidation-mlogloss:0.28995\n",
            "[265]\tvalidation-mlogloss:0.28981\n",
            "[266]\tvalidation-mlogloss:0.28964\n",
            "[267]\tvalidation-mlogloss:0.28944\n",
            "[268]\tvalidation-mlogloss:0.28925\n",
            "[269]\tvalidation-mlogloss:0.28895\n",
            "[270]\tvalidation-mlogloss:0.28877\n",
            "[271]\tvalidation-mlogloss:0.28859\n",
            "[272]\tvalidation-mlogloss:0.28843\n",
            "[273]\tvalidation-mlogloss:0.28821\n",
            "[274]\tvalidation-mlogloss:0.28799\n",
            "[275]\tvalidation-mlogloss:0.28780\n",
            "[276]\tvalidation-mlogloss:0.28761\n",
            "[277]\tvalidation-mlogloss:0.28750\n",
            "[278]\tvalidation-mlogloss:0.28734\n",
            "[279]\tvalidation-mlogloss:0.28711\n",
            "[280]\tvalidation-mlogloss:0.28700\n",
            "[281]\tvalidation-mlogloss:0.28686\n",
            "[282]\tvalidation-mlogloss:0.28663\n",
            "[283]\tvalidation-mlogloss:0.28646\n",
            "[284]\tvalidation-mlogloss:0.28623\n",
            "[285]\tvalidation-mlogloss:0.28613\n",
            "[286]\tvalidation-mlogloss:0.28586\n",
            "[287]\tvalidation-mlogloss:0.28572\n",
            "[288]\tvalidation-mlogloss:0.28562\n",
            "[289]\tvalidation-mlogloss:0.28538\n",
            "[290]\tvalidation-mlogloss:0.28526\n",
            "[291]\tvalidation-mlogloss:0.28509\n",
            "[292]\tvalidation-mlogloss:0.28496\n",
            "[293]\tvalidation-mlogloss:0.28489\n",
            "[294]\tvalidation-mlogloss:0.28469\n",
            "[295]\tvalidation-mlogloss:0.28460\n",
            "[296]\tvalidation-mlogloss:0.28442\n",
            "[297]\tvalidation-mlogloss:0.28436\n",
            "[298]\tvalidation-mlogloss:0.28421\n",
            "[299]\tvalidation-mlogloss:0.28405\n",
            "[300]\tvalidation-mlogloss:0.28393\n",
            "[301]\tvalidation-mlogloss:0.28385\n",
            "[302]\tvalidation-mlogloss:0.28375\n",
            "[303]\tvalidation-mlogloss:0.28359\n",
            "[304]\tvalidation-mlogloss:0.28350\n",
            "[305]\tvalidation-mlogloss:0.28343\n",
            "[306]\tvalidation-mlogloss:0.28318\n",
            "[307]\tvalidation-mlogloss:0.28305\n",
            "[308]\tvalidation-mlogloss:0.28300\n",
            "[309]\tvalidation-mlogloss:0.28289\n",
            "[310]\tvalidation-mlogloss:0.28275\n",
            "[311]\tvalidation-mlogloss:0.28258\n",
            "[312]\tvalidation-mlogloss:0.28242\n",
            "[313]\tvalidation-mlogloss:0.28226\n",
            "[314]\tvalidation-mlogloss:0.28207\n",
            "[315]\tvalidation-mlogloss:0.28201\n",
            "[316]\tvalidation-mlogloss:0.28190\n",
            "[317]\tvalidation-mlogloss:0.28175\n",
            "[318]\tvalidation-mlogloss:0.28165\n",
            "[319]\tvalidation-mlogloss:0.28158\n",
            "[320]\tvalidation-mlogloss:0.28144\n",
            "[321]\tvalidation-mlogloss:0.28128\n",
            "[322]\tvalidation-mlogloss:0.28115\n",
            "[323]\tvalidation-mlogloss:0.28107\n",
            "[324]\tvalidation-mlogloss:0.28094\n",
            "[325]\tvalidation-mlogloss:0.28081\n",
            "[326]\tvalidation-mlogloss:0.28070\n",
            "[327]\tvalidation-mlogloss:0.28055\n",
            "[328]\tvalidation-mlogloss:0.28040\n",
            "[329]\tvalidation-mlogloss:0.28034\n",
            "[330]\tvalidation-mlogloss:0.28028\n",
            "[331]\tvalidation-mlogloss:0.28025\n",
            "[332]\tvalidation-mlogloss:0.28020\n",
            "[333]\tvalidation-mlogloss:0.28010\n",
            "[334]\tvalidation-mlogloss:0.28001\n",
            "[335]\tvalidation-mlogloss:0.27993\n",
            "[336]\tvalidation-mlogloss:0.27981\n",
            "[337]\tvalidation-mlogloss:0.27975\n",
            "[338]\tvalidation-mlogloss:0.27965\n",
            "[339]\tvalidation-mlogloss:0.27950\n",
            "[340]\tvalidation-mlogloss:0.27941\n",
            "[341]\tvalidation-mlogloss:0.27935\n",
            "[342]\tvalidation-mlogloss:0.27931\n",
            "[343]\tvalidation-mlogloss:0.27916\n",
            "[344]\tvalidation-mlogloss:0.27911\n",
            "[345]\tvalidation-mlogloss:0.27902\n",
            "[346]\tvalidation-mlogloss:0.27889\n",
            "[347]\tvalidation-mlogloss:0.27879\n",
            "[348]\tvalidation-mlogloss:0.27861\n",
            "[349]\tvalidation-mlogloss:0.27855\n",
            "[350]\tvalidation-mlogloss:0.27847\n",
            "[351]\tvalidation-mlogloss:0.27843\n",
            "[352]\tvalidation-mlogloss:0.27833\n",
            "[353]\tvalidation-mlogloss:0.27824\n",
            "[354]\tvalidation-mlogloss:0.27818\n",
            "[355]\tvalidation-mlogloss:0.27806\n",
            "[356]\tvalidation-mlogloss:0.27796\n",
            "[357]\tvalidation-mlogloss:0.27791\n",
            "[358]\tvalidation-mlogloss:0.27786\n",
            "[359]\tvalidation-mlogloss:0.27776\n",
            "[360]\tvalidation-mlogloss:0.27769\n",
            "[361]\tvalidation-mlogloss:0.27765\n",
            "[362]\tvalidation-mlogloss:0.27760\n",
            "[363]\tvalidation-mlogloss:0.27748\n",
            "[364]\tvalidation-mlogloss:0.27737\n",
            "[365]\tvalidation-mlogloss:0.27726\n",
            "[366]\tvalidation-mlogloss:0.27719\n",
            "[367]\tvalidation-mlogloss:0.27717\n",
            "[368]\tvalidation-mlogloss:0.27713\n",
            "[369]\tvalidation-mlogloss:0.27704\n",
            "[370]\tvalidation-mlogloss:0.27703\n",
            "[371]\tvalidation-mlogloss:0.27695\n",
            "[372]\tvalidation-mlogloss:0.27685\n",
            "[373]\tvalidation-mlogloss:0.27688\n",
            "[374]\tvalidation-mlogloss:0.27685\n",
            "[375]\tvalidation-mlogloss:0.27679\n",
            "[376]\tvalidation-mlogloss:0.27672\n",
            "[377]\tvalidation-mlogloss:0.27670\n",
            "[378]\tvalidation-mlogloss:0.27669\n",
            "[379]\tvalidation-mlogloss:0.27655\n",
            "[380]\tvalidation-mlogloss:0.27644\n",
            "[381]\tvalidation-mlogloss:0.27637\n",
            "[382]\tvalidation-mlogloss:0.27630\n",
            "[383]\tvalidation-mlogloss:0.27626\n",
            "[384]\tvalidation-mlogloss:0.27615\n",
            "[385]\tvalidation-mlogloss:0.27613\n",
            "[386]\tvalidation-mlogloss:0.27596\n",
            "[387]\tvalidation-mlogloss:0.27591\n",
            "[388]\tvalidation-mlogloss:0.27585\n",
            "[389]\tvalidation-mlogloss:0.27571\n",
            "[390]\tvalidation-mlogloss:0.27565\n",
            "[391]\tvalidation-mlogloss:0.27563\n",
            "[392]\tvalidation-mlogloss:0.27561\n",
            "[393]\tvalidation-mlogloss:0.27553\n",
            "[394]\tvalidation-mlogloss:0.27549\n",
            "[395]\tvalidation-mlogloss:0.27541\n",
            "[396]\tvalidation-mlogloss:0.27536\n",
            "[397]\tvalidation-mlogloss:0.27538\n",
            "[398]\tvalidation-mlogloss:0.27533\n",
            "[399]\tvalidation-mlogloss:0.27518\n",
            "[400]\tvalidation-mlogloss:0.27514\n",
            "[401]\tvalidation-mlogloss:0.27511\n",
            "[402]\tvalidation-mlogloss:0.27511\n",
            "[403]\tvalidation-mlogloss:0.27511\n",
            "[404]\tvalidation-mlogloss:0.27511\n",
            "[405]\tvalidation-mlogloss:0.27506\n",
            "[406]\tvalidation-mlogloss:0.27502\n",
            "[407]\tvalidation-mlogloss:0.27499\n",
            "[408]\tvalidation-mlogloss:0.27493\n",
            "[409]\tvalidation-mlogloss:0.27497\n",
            "[410]\tvalidation-mlogloss:0.27492\n",
            "[411]\tvalidation-mlogloss:0.27489\n",
            "[412]\tvalidation-mlogloss:0.27485\n",
            "[413]\tvalidation-mlogloss:0.27483\n",
            "[414]\tvalidation-mlogloss:0.27478\n",
            "[415]\tvalidation-mlogloss:0.27477\n",
            "[416]\tvalidation-mlogloss:0.27477\n",
            "[417]\tvalidation-mlogloss:0.27471\n",
            "[418]\tvalidation-mlogloss:0.27468\n",
            "[419]\tvalidation-mlogloss:0.27466\n",
            "[420]\tvalidation-mlogloss:0.27465\n",
            "[421]\tvalidation-mlogloss:0.27462\n",
            "[422]\tvalidation-mlogloss:0.27455\n",
            "[423]\tvalidation-mlogloss:0.27455\n",
            "[424]\tvalidation-mlogloss:0.27454\n",
            "[425]\tvalidation-mlogloss:0.27448\n",
            "[426]\tvalidation-mlogloss:0.27450\n",
            "[427]\tvalidation-mlogloss:0.27447\n",
            "[428]\tvalidation-mlogloss:0.27447\n",
            "[429]\tvalidation-mlogloss:0.27448\n",
            "[430]\tvalidation-mlogloss:0.27451\n",
            "[431]\tvalidation-mlogloss:0.27446\n",
            "[432]\tvalidation-mlogloss:0.27443\n",
            "[433]\tvalidation-mlogloss:0.27441\n",
            "[434]\tvalidation-mlogloss:0.27441\n",
            "[435]\tvalidation-mlogloss:0.27439\n",
            "[436]\tvalidation-mlogloss:0.27428\n",
            "[437]\tvalidation-mlogloss:0.27428\n",
            "[438]\tvalidation-mlogloss:0.27421\n",
            "[439]\tvalidation-mlogloss:0.27422\n",
            "[440]\tvalidation-mlogloss:0.27421\n",
            "[441]\tvalidation-mlogloss:0.27420\n",
            "[442]\tvalidation-mlogloss:0.27417\n",
            "[443]\tvalidation-mlogloss:0.27415\n",
            "[444]\tvalidation-mlogloss:0.27409\n",
            "[445]\tvalidation-mlogloss:0.27407\n",
            "[446]\tvalidation-mlogloss:0.27403\n",
            "[447]\tvalidation-mlogloss:0.27398\n",
            "[448]\tvalidation-mlogloss:0.27395\n",
            "[449]\tvalidation-mlogloss:0.27391\n",
            "[450]\tvalidation-mlogloss:0.27388\n",
            "[451]\tvalidation-mlogloss:0.27384\n",
            "[452]\tvalidation-mlogloss:0.27376\n",
            "[453]\tvalidation-mlogloss:0.27375\n",
            "[454]\tvalidation-mlogloss:0.27372\n",
            "[455]\tvalidation-mlogloss:0.27369\n",
            "[456]\tvalidation-mlogloss:0.27369\n",
            "[457]\tvalidation-mlogloss:0.27366\n",
            "[458]\tvalidation-mlogloss:0.27364\n",
            "[459]\tvalidation-mlogloss:0.27362\n",
            "[460]\tvalidation-mlogloss:0.27357\n",
            "[461]\tvalidation-mlogloss:0.27352\n",
            "[462]\tvalidation-mlogloss:0.27347\n",
            "[463]\tvalidation-mlogloss:0.27344\n",
            "[464]\tvalidation-mlogloss:0.27344\n",
            "[465]\tvalidation-mlogloss:0.27341\n",
            "[466]\tvalidation-mlogloss:0.27341\n",
            "[467]\tvalidation-mlogloss:0.27340\n",
            "[468]\tvalidation-mlogloss:0.27336\n",
            "[469]\tvalidation-mlogloss:0.27340\n",
            "[470]\tvalidation-mlogloss:0.27342\n",
            "[471]\tvalidation-mlogloss:0.27338\n",
            "[472]\tvalidation-mlogloss:0.27336\n",
            "[473]\tvalidation-mlogloss:0.27337\n",
            "[474]\tvalidation-mlogloss:0.27330\n",
            "[475]\tvalidation-mlogloss:0.27328\n",
            "[476]\tvalidation-mlogloss:0.27327\n",
            "[477]\tvalidation-mlogloss:0.27321\n",
            "[478]\tvalidation-mlogloss:0.27321\n",
            "[479]\tvalidation-mlogloss:0.27316\n",
            "[480]\tvalidation-mlogloss:0.27313\n",
            "[481]\tvalidation-mlogloss:0.27315\n",
            "[482]\tvalidation-mlogloss:0.27311\n",
            "[483]\tvalidation-mlogloss:0.27302\n",
            "[484]\tvalidation-mlogloss:0.27299\n",
            "[485]\tvalidation-mlogloss:0.27300\n",
            "[486]\tvalidation-mlogloss:0.27301\n",
            "[487]\tvalidation-mlogloss:0.27300\n",
            "[488]\tvalidation-mlogloss:0.27302\n",
            "[489]\tvalidation-mlogloss:0.27301\n",
            "[490]\tvalidation-mlogloss:0.27296\n",
            "[491]\tvalidation-mlogloss:0.27295\n",
            "[492]\tvalidation-mlogloss:0.27291\n",
            "[493]\tvalidation-mlogloss:0.27290\n",
            "[494]\tvalidation-mlogloss:0.27291\n",
            "[495]\tvalidation-mlogloss:0.27288\n",
            "[496]\tvalidation-mlogloss:0.27283\n",
            "[497]\tvalidation-mlogloss:0.27279\n",
            "[498]\tvalidation-mlogloss:0.27276\n",
            "[499]\tvalidation-mlogloss:0.27277\n",
            "[500]\tvalidation-mlogloss:0.27275\n",
            "[501]\tvalidation-mlogloss:0.27271\n",
            "[502]\tvalidation-mlogloss:0.27271\n",
            "[503]\tvalidation-mlogloss:0.27271\n",
            "[504]\tvalidation-mlogloss:0.27272\n",
            "[505]\tvalidation-mlogloss:0.27268\n",
            "[506]\tvalidation-mlogloss:0.27265\n",
            "[507]\tvalidation-mlogloss:0.27264\n",
            "[508]\tvalidation-mlogloss:0.27264\n",
            "[509]\tvalidation-mlogloss:0.27262\n",
            "[510]\tvalidation-mlogloss:0.27265\n",
            "[511]\tvalidation-mlogloss:0.27263\n",
            "[512]\tvalidation-mlogloss:0.27258\n",
            "[513]\tvalidation-mlogloss:0.27260\n",
            "[514]\tvalidation-mlogloss:0.27262\n",
            "[515]\tvalidation-mlogloss:0.27261\n",
            "[516]\tvalidation-mlogloss:0.27257\n",
            "[517]\tvalidation-mlogloss:0.27255\n",
            "[518]\tvalidation-mlogloss:0.27251\n",
            "[519]\tvalidation-mlogloss:0.27251\n",
            "[520]\tvalidation-mlogloss:0.27249\n",
            "[521]\tvalidation-mlogloss:0.27251\n",
            "[522]\tvalidation-mlogloss:0.27250\n",
            "[523]\tvalidation-mlogloss:0.27249\n",
            "[524]\tvalidation-mlogloss:0.27247\n",
            "[525]\tvalidation-mlogloss:0.27249\n",
            "[526]\tvalidation-mlogloss:0.27247\n",
            "[527]\tvalidation-mlogloss:0.27248\n",
            "[528]\tvalidation-mlogloss:0.27245\n",
            "[529]\tvalidation-mlogloss:0.27249\n",
            "[530]\tvalidation-mlogloss:0.27251\n",
            "[531]\tvalidation-mlogloss:0.27255\n",
            "[532]\tvalidation-mlogloss:0.27253\n",
            "[533]\tvalidation-mlogloss:0.27252\n",
            "[534]\tvalidation-mlogloss:0.27253\n",
            "[535]\tvalidation-mlogloss:0.27251\n",
            "[536]\tvalidation-mlogloss:0.27252\n",
            "[537]\tvalidation-mlogloss:0.27254\n",
            "[538]\tvalidation-mlogloss:0.27254\n",
            "[539]\tvalidation-mlogloss:0.27253\n",
            "[540]\tvalidation-mlogloss:0.27254\n",
            "[541]\tvalidation-mlogloss:0.27257\n",
            "[542]\tvalidation-mlogloss:0.27260\n",
            "[543]\tvalidation-mlogloss:0.27258\n",
            "[544]\tvalidation-mlogloss:0.27259\n",
            "[545]\tvalidation-mlogloss:0.27260\n",
            "[546]\tvalidation-mlogloss:0.27261\n",
            "[547]\tvalidation-mlogloss:0.27262\n",
            "[548]\tvalidation-mlogloss:0.27265\n",
            "üéØ Validation Accuracy: 90.5697%\n",
            "\n",
            "üìä Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       374\n",
            "           1       0.88      0.89      0.89       469\n",
            "           2       0.90      0.87      0.88       441\n",
            "           3       0.96      0.98      0.97       481\n",
            "           4       0.99      1.00      0.99       597\n",
            "           5       0.82      0.75      0.79       369\n",
            "           6       0.80      0.85      0.82       376\n",
            "\n",
            "    accuracy                           0.91      3107\n",
            "   macro avg       0.90      0.90      0.90      3107\n",
            "weighted avg       0.91      0.91      0.91      3107\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_sets = {\n",
        "    \"Tuned C\": {\n",
        "        \"n_estimators\": 650,\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"max_depth\": 8,\n",
        "        \"subsample\": 0.75,\n",
        "        \"colsample_bytree\": 0.8,\n",
        "        \"gamma\": 0.4,\n",
        "        \"min_child_weight\": 2,\n",
        "        \"reg_alpha\": 0.6,\n",
        "        \"reg_lambda\": 1.2,\n",
        "    },\n",
        "    \"Tuned D\": {\n",
        "        \"n_estimators\": 700,\n",
        "        \"learning_rate\": 0.018,\n",
        "        \"max_depth\": 7,\n",
        "        \"subsample\": 0.7,\n",
        "        \"colsample_bytree\": 0.75,\n",
        "        \"gamma\": 0.3,\n",
        "        \"min_child_weight\": 3,\n",
        "        \"reg_alpha\": 0.5,\n",
        "        \"reg_lambda\": 1.0,\n",
        "    },\n",
        "    \"Tuned E\": {\n",
        "        \"n_estimators\": 600,\n",
        "        \"learning_rate\": 0.015,\n",
        "        \"max_depth\": 6,\n",
        "        \"subsample\": 0.8,\n",
        "        \"colsample_bytree\": 0.85,\n",
        "        \"gamma\": 0.2,\n",
        "        \"min_child_weight\": 1,\n",
        "        \"reg_alpha\": 0.4,\n",
        "        \"reg_lambda\": 0.8,\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "slI07igg1WVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in param_sets.items():\n",
        "    model = XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=len(np.unique(y_train)),\n",
        "        eval_metric=\"mlogloss\",\n",
        "        use_label_encoder=False,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    val_pred = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, val_pred)\n",
        "    print(f\"{name} Validation Accuracy: {acc * 100:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_FmlVy32JxI",
        "outputId": "073cd08f-2a27-4d9d-cf22-4e769bbdc7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [04:50:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned C Validation Accuracy: 90.4409%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [04:50:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned D Validation Accuracy: 90.6019%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [04:50:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned E Validation Accuracy: 90.4088%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# ‚úÖ Imports and Setup\n",
        "# =============================================\n",
        "!pip install xgboost scikit-learn pandas --quiet\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"üìú Final model script initialized.\")\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ Load Data\n",
        "# =============================================\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    train_df = pd.read_csv(\"train.csv\")\n",
        "    test_df = pd.read_csv(\"test.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: train.csv or test.csv not found.\")\n",
        "    # In a real script, you might exit here\n",
        "    # exit()\n",
        "\n",
        "X = train_df.drop(columns=[\"WeightCategory\", \"id\"])\n",
        "y_labels = train_df[\"WeightCategory\"]\n",
        "X_test = test_df.drop(columns=[\"id\"])\n",
        "test_ids = test_df[\"id\"].copy()\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ Feature Engineering & Preprocessing\n",
        "# =============================================\n",
        "print(\"‚öôÔ∏è Processing features...\")\n",
        "\n",
        "# --- 1. DEFINE FEATURE ENGINEERING FUNCTION ---\n",
        "def create_features(df):\n",
        "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
        "    df['Activity_Ratio'] = df['FAF'] / (df['TUE'] + 1e-6)\n",
        "    df['Veg_per_Meal'] = df['FCVC'] / (df['NCP'] + 1e-6)\n",
        "    df['Age_sq'] = df['Age'] ** 2\n",
        "    return df\n",
        "\n",
        "# --- 2. APPLY FEATURE ENGINEERING ---\n",
        "print(\"Creating new features...\")\n",
        "X = create_features(X)\n",
        "X_test = create_features(X_test)\n",
        "print(\"New features created: ['BMI', 'Activity_Ratio', 'Veg_per_Meal', 'Age_sq']\")\n",
        "\n",
        "# --- 3. PREPROCESSING ---\n",
        "# 3a. Encode Target\n",
        "le_target = LabelEncoder()\n",
        "y = le_target.fit_transform(y_labels)\n",
        "num_classes = len(le_target.classes_)\n",
        "\n",
        "# 3b. Combine train/test for consistent dummy encoding\n",
        "combined_df = pd.concat([X, X_test], axis=0)\n",
        "combined_df = pd.get_dummies(combined_df, drop_first=True)\n",
        "\n",
        "# 3c. Separate back into train/test\n",
        "X = combined_df.iloc[:len(X)]\n",
        "X_test = combined_df.iloc[len(X):]\n",
        "\n",
        "# 3d. Scale numerical features\n",
        "numeric_cols = X.select_dtypes(include=np.number).columns\n",
        "scaler = StandardScaler()\n",
        "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "# 3e. Ensure column names are strings (for XGBoost)\n",
        "X.columns = X.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)\n",
        "print(\"‚úÖ Features processed and scaled.\")\n",
        "\n",
        "# =============================================\n",
        "# ‚úÖ Train Final Model & Create Submission\n",
        "# =============================================\n",
        "print(\"\\nüèÅ Starting final model training...\")\n",
        "\n",
        "# --- 1. Hard-code your BEST parameters from Trial 203 ---\n",
        "best_params = {\n",
        "    \"objective\": \"multi:softmax\",\n",
        "    \"num_class\": num_classes,\n",
        "    \"eval_metric\": \"mlogloss\",\n",
        "    \"verbosity\": 1, # Set to 1 to see it train\n",
        "    \"seed\": 42,\n",
        "    \"tree_method\": \"hist\",\n",
        "\n",
        "    # These are from your 'Best is trial 203' log\n",
        "    \"eta\": 0.06794898540089923,\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 1,\n",
        "    \"subsample\": 0.7953386026614067,\n",
        "    \"colsample_bytree\": 0.6417557307124112,\n",
        "    \"gamma\": 0.6758030233248484,\n",
        "    \"alpha\": 0.11467350881393687,\n",
        "    \"lambda\": 1.407102951104466\n",
        "}\n",
        "\n",
        "# This was the 'n_estimators' *budget* for your best trial.\n",
        "# We will use this as the number of trees for the final model.\n",
        "best_n_estimators = 783\n",
        "\n",
        "print(\"\\nFinal Model Parameters:\")\n",
        "for k, v in best_params.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"  n_estimators (num_boost_round): {best_n_estimators}\")\n",
        "\n",
        "# --- 2. Train on FULL Data ---\n",
        "print(\"\\nüèãÔ∏è Training final model on ALL data...\")\n",
        "# Create DMatrix on the *entire* training set\n",
        "dtrain_full = xgb.DMatrix(X, label=y, weight=compute_sample_weight(class_weight='balanced', y=y))\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "final_model_bst = xgb.train(\n",
        "    best_params,\n",
        "    dtrain_full,\n",
        "    num_boost_round=best_n_estimators, # Use the number of estimators from your best trial\n",
        "    verbose_eval=50 # Print progress every 50 trees\n",
        ")\n",
        "\n",
        "# --- 3. Generate Predictions ---\n",
        "print(\"\\nüìä Generating predictions...\")\n",
        "predictions_numeric = final_model_bst.predict(dtest).astype(int)\n",
        "\n",
        "# Decode predictions back to original labels\n",
        "predictions_labels = le_target.inverse_transform(predictions_numeric)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_ids,\n",
        "    \"WeightCategory\": predictions_labels\n",
        "})\n",
        "submission_filename = \"submission_FINAL_v1.csv\"\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"üìÅ {submission_filename} saved successfully! Submit this file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fF0AhH9X3_D",
        "outputId": "bbcf6667-ea3c-44bb-ddd1-946a06ce1f0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìú Final model script initialized.\n",
            "Loading data...\n",
            "‚öôÔ∏è Processing features...\n",
            "Creating new features...\n",
            "New features created: ['BMI', 'Activity_Ratio', 'Veg_per_Meal', 'Age_sq']\n",
            "‚úÖ Features processed and scaled.\n",
            "\n",
            "üèÅ Starting final model training...\n",
            "\n",
            "Final Model Parameters:\n",
            "  objective: multi:softmax\n",
            "  num_class: 7\n",
            "  eval_metric: mlogloss\n",
            "  verbosity: 1\n",
            "  seed: 42\n",
            "  tree_method: hist\n",
            "  eta: 0.06794898540089923\n",
            "  max_depth: 5\n",
            "  min_child_weight: 1\n",
            "  subsample: 0.7953386026614067\n",
            "  colsample_bytree: 0.6417557307124112\n",
            "  gamma: 0.6758030233248484\n",
            "  alpha: 0.11467350881393687\n",
            "  lambda: 1.407102951104466\n",
            "  n_estimators (num_boost_round): 783\n",
            "\n",
            "üèãÔ∏è Training final model on ALL data...\n",
            "\n",
            "üìä Generating predictions...\n",
            "üìÅ submission_FINAL_v1.csv saved successfully! Submit this file.\n"
          ]
        }
      ]
    }
  ]
}